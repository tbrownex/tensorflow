{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a CNN for image recognition\n",
    "Images are rectangles in the foreground and various backgrounds as noise. The goal is to determine the orientation of the image, horizontal or vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "IMAGE_HEIGHT  = 28\n",
    "IMAGE_WIDTH   = 28\n",
    "CHANNELS      = 1\n",
    "NUM_CLASSES   = 2                       # Vertical or Horizontal alignment\n",
    "BATCH_SIZE    = 128\n",
    "EPOCHS        = 2\n",
    "LEARNING_RATE = .0003\n",
    "DROPOUT       = True                   # Toggle to dropout or not\n",
    "DROPOUT_KEEP  = 0.6\n",
    "POOL1         = False\n",
    "POOL2         = True\n",
    "TEST_PCT      = 0.15\n",
    "VALID_PCT     = 0.15                    # Validation is 20% of remaining (after Test)\n",
    "DATA_DIR      = '/home/tom/data/'\n",
    "FILENAME      = 'rectangles-images.txt'\n",
    "SUMMARIES_DIR = '/home/tom/tflogs'     # where to store Summary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Both the data and the label are in the passed dataframe\n",
    "# Split them apart and put into numpy array\n",
    "def split_label(df):\n",
    "    labels = np.array(df['label'], dtype='f')\n",
    "    # convert labels to a \"one-hot\" vector\n",
    "    labels = (np.arange(NUM_CLASSES) == labels[:, None]).astype(np.float32)\n",
    "\n",
    "    data = df.iloc[:,:len(df.columns)-1]\n",
    "    # Turn \"data\" into a np array which will be used to load the tensor\n",
    "    data = np.array(data, dtype='f')\n",
    "    data = np.reshape(data, [len(df),IMAGE_HEIGHT,IMAGE_WIDTH,CHANNELS])\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 62,000 rows and 785 columns\n"
     ]
    }
   ],
   "source": [
    "# Data consists of images of rectangles, 28x28, single channel\n",
    "df = pd.read_csv(DATA_DIR + FILENAME)\n",
    "print('data has {:,} rows and {} columns'.format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:    44,795 rows\n",
      "Validation:  7,905 rows\n",
      "Test:        9,300 rows\n"
     ]
    }
   ],
   "source": [
    "# Split incoming data into Train/Validation/Test\n",
    "df_train, df_test = train_test_split(df, test_size=TEST_PCT)\n",
    "df_train, df_val  = train_test_split(df_train, test_size=VALID_PCT)\n",
    "print('Training:    {:,} rows'.format(df_train.shape[0]))\n",
    "print('Validation:  {:,} rows'.format(df_val.shape[0]))\n",
    "print('Test:        {:,} rows'.format(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the features from the labels\n",
    "train_data, train_labels = split_label(df_train)\n",
    "val_data,   val_labels = split_label(df_val)\n",
    "test_data,  test_labels  = split_label(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_batch = tf.placeholder(tf.float32, shape=[None,IMAGE_HEIGHT,IMAGE_WIDTH,CHANNELS])\n",
    "label_batch = tf.placeholder(tf.float32, shape=[None,NUM_CLASSES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(img, size, depth, filters, strides):\n",
    "    weight = tf.Variable(tf.truncated_normal(shape=[size, size, depth, filters], stddev=0.3))\n",
    "    bias   = tf.Variable(tf.truncated_normal([filters]))\n",
    "    print(img.get_shape())\n",
    "    print(weight.get_shape())\n",
    "    conv   = tf.nn.conv2d(input=img,\n",
    "                          filter=weight,\n",
    "                          strides=[1,strides,strides,1],\n",
    "                          padding='SAME')\n",
    "    print(conv.get_shape())\n",
    "    conv = tf.nn.bias_add(conv, bias)\n",
    "    return tf.nn.relu(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 1)\n",
      "(3, 3, 1, 32)\n",
      "(?, 28, 28, 32)\n"
     ]
    }
   ],
   "source": [
    "L1size    = 3            # size of a filter\n",
    "L1depth   = CHANNELS\n",
    "L1filters = 32           # number of filters\n",
    "L1strides = 1\n",
    "l1_out        = conv_layer(image_batch, L1size, L1depth, L1filters, L1strides)\n",
    "if POOL1:\n",
    "    l1_out    = tf.nn.max_pool(value=l1_out,\n",
    "                           ksize=[1,2,2,1],\n",
    "                           strides=[1,2,2,1],\n",
    "                           padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 32)\n",
      "(3, 3, 32, 64)\n",
      "(?, 28, 28, 64)\n"
     ]
    }
   ],
   "source": [
    "L2size    = 3            # size of a filter\n",
    "L2depth   = L1filters\n",
    "L2filters = 64           # number of filters\n",
    "L2strides = 1\n",
    "l2_out    = conv_layer(l1_out, L2size, L2depth, L2filters, L2strides)\n",
    "if POOL2:\n",
    "    l2_out = tf.nn.max_pool(value=l2_out,\n",
    "                            ksize=[1,2,2,1],\n",
    "                            strides=[1,2,2,1],\n",
    "                            padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reshape to allow conversion to Fully Connected layer\n",
    "L2_flat = tf.reshape(l2_out, [-1, 14*14*L2filters])\n",
    "\n",
    "FCw    = tf.Variable(tf.truncated_normal(shape=[14*14*L2filters,32], stddev=0.3))\n",
    "FCb    = tf.Variable(tf.truncated_normal([32]))\n",
    "fc      = tf.matmul(L2_flat, FCw) + FCb\n",
    "fc_out  = tf.nn.relu(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OLw    = tf.Variable(tf.truncated_normal(shape=[32,NUM_CLASSES], stddev=0.3))\n",
    "OLb    = tf.Variable(tf.truncated_normal([NUM_CLASSES]))\n",
    "ol     = tf.matmul(fc_out, OLw) + OLb\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "if DROPOUT:\n",
    "    ol = tf.nn.dropout(ol, keep_prob)\n",
    "    \n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(ol, label_batch))\n",
    "optimize = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(ol,1), tf.argmax(label_batch,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Playing WAVE '/usr/share/sounds/chime_down.wav' : Unsigned 8 bit, Rate 11025 Hz, Mono\n",
      "Epoch 2\n",
      "Playing WAVE '/usr/share/sounds/chime_down.wav' : Unsigned 8 bit, Rate 11025 Hz, Mono\n",
      "Accuracy against test set: 57.2%\n",
      "Elapsed time: 26.0 minutes\n",
      "Playing WAVE '/usr/share/sounds/bicycle_bell.wav' : Signed 16 bit Little Endian, Rate 11127 Hz, Mono\n"
     ]
    }
   ],
   "source": [
    "# Capture Tensorboard data\n",
    "summary_loss = tf.scalar_summary('Loss function', loss)\n",
    "summary_accuracy = tf.scalar_summary('accuracy', accuracy)\n",
    "\n",
    "num_training_batches = int(len(train_data) / BATCH_SIZE)\n",
    "\n",
    "start = time.time()\n",
    "count = 0                           # For Tensorboard\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    train_writer = tf.train.SummaryWriter(SUMMARIES_DIR + '/train/'+'LearnRate', sess.graph)\n",
    "    test_writer = tf.train.SummaryWriter(SUMMARIES_DIR + '/test/'+'LearnRate', sess.graph)\n",
    "    for i in range(EPOCHS):\n",
    "        x,y = shuffle(train_data,train_labels)\n",
    "        print('Epoch {}'.format(i+1))\n",
    "        for j in range(num_training_batches):\n",
    "            x_mini = x[j*BATCH_SIZE:j*BATCH_SIZE+BATCH_SIZE]\n",
    "            y_mini = y[j*BATCH_SIZE:j*BATCH_SIZE+BATCH_SIZE]\n",
    "            _, tb = sess.run([optimize, summary_loss], feed_dict={\n",
    "                image_batch:x_mini,\n",
    "                label_batch:y_mini,\n",
    "                keep_prob:DROPOUT_KEEP})\n",
    "            if j % 20 ==0:      \n",
    "                count += 1                \n",
    "                train_writer.add_summary(tb, count)\n",
    "                _, tb = sess.run([accuracy, summary_accuracy], feed_dict={\n",
    "                        image_batch:val_data,\n",
    "                        label_batch:val_labels,\n",
    "                        keep_prob:1.0})\n",
    "                test_writer.add_summary(tb, count)\n",
    "        !aplay /usr/share/sounds/chime_down.wav\n",
    "    # Training is done, run the test\n",
    "    score = sess.run(accuracy, feed_dict={\n",
    "                image_batch:test_data,\n",
    "                label_batch:test_labels,\n",
    "                keep_prob:1.0})\n",
    "    print('Accuracy against test set: {:.1%}'.format(score))\n",
    "train_writer.close()\n",
    "test_writer.close()\n",
    "print('Elapsed time: {} minutes'.format((time.time() - start)//60))\n",
    "!aplay /usr/share/sounds/bicycle_bell.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
