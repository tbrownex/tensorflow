{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From this book, about page 920: http://hagan.okstate.edu/NNDesign.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform non-linear regression against a small dataset of 67 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "L1_SIZE        = 15            # How many nodes in layer 1\n",
    "EPOCHS         = 2000\n",
    "TEST_PCT       = 0.20\n",
    "VAL_PCT        = 0.10\n",
    "FEATURE_COUNT  = 2\n",
    "BATCH_SIZE     = 12\n",
    "LEARNING_RATE  = .001\n",
    "SUMMARIES_DIR  = '/home/tom/tf_logs' # where to store Tensorboard data\n",
    "L2             = True\n",
    "LAMBDA         = 0.2              # Regularization parameter\n",
    "DROPOUT_KEEP   = 1.0\n",
    "PLOT           = False\n",
    "SYNTHETIC      = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if sys.platform[:3] =='win':\n",
    "    data_loc = 'D:/Data/'\n",
    "else:\n",
    "    data_loc = \"/home/tom/data/\"\n",
    "\n",
    "filenm = \"haganCaseStudy1.csv\"\n",
    "df = pd.read_csv(data_loc+filenm, delimiter = ',')\n",
    "\n",
    "# v1 and v2 is the voltage coming out of the 2 solar cells\n",
    "# y is the position of the ping pong ball (in front of a light)\n",
    "before = df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create some synthetic data so we have good quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if SYNTHETIC:\n",
    "    orig = df.copy()\n",
    "    for x in range(10):\n",
    "        df_copy = orig.copy()\n",
    "        df_copy['v1'] = df_copy['v1'] + np.divide(np.random.randn(),10)\n",
    "        df_copy['v2'] = df_copy['v2'] + np.divide(np.random.randn(),10)\n",
    "        df_copy['y'] = df_copy['y'] + np.divide(np.random.randn(),30)\n",
    "        df = df.append(df_copy)\n",
    "# Set any negative values to 0\n",
    "    negs = df['v1']<0\n",
    "    df['v1'][negs]=0\n",
    "    negs = df['v2']<0\n",
    "    df['v2'][negs]=0\n",
    "    after = df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "v1     = df['v1'].values.reshape(-1,1)\n",
    "v1_std = StandardScaler().fit_transform(v1)\n",
    "v2     = df['v2'].values.reshape(-1,1)\n",
    "v2_std = StandardScaler().fit_transform(v2)\n",
    "y      = df['y'].values.reshape(-1,1)\n",
    "y_std  = StandardScaler().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split into train, val and test\n",
    "# Recombine into DF\n",
    "arr = np.concatenate([v1_std,v2_std,y_std], axis=1)\n",
    "cols = ['v1','v2','y']\n",
    "df = pd.DataFrame(arr, columns=cols)\n",
    "\n",
    "train, test = train_test_split(df, test_size=TEST_PCT)\n",
    "train, val  = train_test_split(df, test_size=VAL_PCT)\n",
    "print('Training:   {:,} rows'.format(train.shape[0]))\n",
    "print('Validation: {:,} rows'.format(val.shape[0]))\n",
    "print('Test:       {:,} rows'.format(test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data   = train[['v1', 'v2']]\n",
    "train_labels = train[['y']]\n",
    "val_data     = val[['v1', 'v2']]\n",
    "val_labels   = val[['y']]\n",
    "test_data    = test[['v1', 'v2']]\n",
    "test_labels  = test[['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See what the data looks like\n",
    "if PLOT:\n",
    "    a = plt.scatter(y_std[:2000], v1_std[:2000], s=1, color='blue',label='Voltage1')\n",
    "    b = plt.scatter(y_std[:2000], v2_std[:2000], s=1, color='red', label='Voltage2')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('Position', fontsize=12)\n",
    "    plt.ylabel('Voltages', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the network\n",
    "tf.reset_default_graph()\n",
    "x       = tf.placeholder(\"float\", shape=[None, FEATURE_COUNT])\n",
    "y_      = tf.placeholder(\"float\", shape=[None, 1])\n",
    "dropout = tf.placeholder(\"float\")\n",
    "\n",
    "l1_w   = tf.Variable(tf.truncated_normal([FEATURE_COUNT, L1_SIZE]), dtype=tf.float32)\n",
    "l1_b   = tf.zeros([1, L1_SIZE])\n",
    "l1_out = tf.nn.tanh(tf.matmul(x,l1_w + l1_b))\n",
    "l1_out = tf.nn.dropout(l1_out, keep_prob=dropout)\n",
    "\n",
    "l2_w   = tf.Variable(tf.truncated_normal([L1_SIZE, 1]), dtype=tf.float32)\n",
    "l2_b   = tf.zeros([1,1])\n",
    "l2_out = tf.matmul(l1_out, l2_w + l2_b)\n",
    "if L2:\n",
    "    cost = (tf.reduce_mean(tf.square(l2_out - y_) + LAMBDA * tf.nn.l2_loss(l1_w)))\n",
    "else:\n",
    "    cost = tf.reduce_sum(tf.square(l2_out - y_))\n",
    "\n",
    "# Optimizer\n",
    "optimize = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(cost)\n",
    "\n",
    "tf.scalar_summary('cost', cost)\n",
    "\n",
    "merged = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 1\n",
    "num_training_batches = int(len(train_data) / BATCH_SIZE)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('DROPOUT: {:%}'.format(DROPOUT_KEEP))\n",
    "    print('Regularization is {}'.format(L2))\n",
    "    train_writer = tf.train.SummaryWriter(SUMMARIES_DIR + '/run3', sess.graph)\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    for i in range(EPOCHS):\n",
    "        data,labels = shuffle(train_data, train_labels)\n",
    "        for j in range(num_training_batches):\n",
    "            x_mini = data[j*BATCH_SIZE:j*BATCH_SIZE+BATCH_SIZE]\n",
    "            y_mini = labels[j*BATCH_SIZE:j*BATCH_SIZE+BATCH_SIZE]\n",
    "            sess.run(optimize, feed_dict = {x: x_mini, y_: y_mini, dropout:DROPOUT_KEEP})\n",
    "        _, s = sess.run([cost, merged], feed_dict = {x: val_data,y_: val_labels, dropout:1.0,})\n",
    "        if j % 10 == 0:\n",
    "            train_writer.add_summary(s, count)\n",
    "            count += 1\n",
    "    s, preds = sess.run([cost, l2_out], feed_dict = {x: test_data, y_: test_labels, dropout:1.0})\n",
    "    print('Test set accuracy: {:.3}'.format(s))\n",
    "    train_writer.close()\n",
    "    !aplay /usr/share/sounds/bicycle_bell.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See what the data looks like\n",
    "PLOT = True\n",
    "if PLOT:\n",
    "    a = plt.scatter(preds, test_data['v2'], s=1, color='blue',label='Voltage1')\n",
    "    b = plt.scatter(test_labels, test_data['v2'], s=1, color='red', label='Voltage2')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('Position', fontsize=12)\n",
    "    plt.ylabel('Voltages', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
